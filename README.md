# 2024_ia651_gyimah â€“ Populationâ€‘Aware VariantÂ Classification

> **Course**: IAâ€‘651Â â€¢ **Authors**: SimonÂ Gyimah   
> **Goal**: build, benchmark & interpret machineâ€‘learning models that predict the *clinical significance* of human genetic variants **while accounting for ancestryâ€‘specific features**.

---
## ğŸ—‚ï¸Â TableÂ ofÂ Contents
1. [Project Overview](#1-overview)
2. [Dataset & Nullâ€‘Filtering](#2-dataset--null-filtering)
3. [Prediction Task](#3-prediction-task)
4. [Process Narrative](#4-process-overview)
5. [EDAÂ Highlights](#5-exploratory-data-analysis-eda)
6. [Feature Engineering](#6-feature-engineering)
7. [Modelling Pipeline](#7-model-fitting--hyperparameter-tuning)
8. [Evaluation & Fairness](#8-validation--performance-metrics)
9. [ProductionÂ /Â CLI Usage](#9-production--deployment)
10. [LimitationsÂ &Â FutureÂ Work](#10-limitations--future-improvements)
11. [Reproducibility](#11-reproducing-this-project)

---
## 1Â Â Overview<a name="1-overview"></a>
Humanâ€‘genome databases such as **ClinVar** and **gnomAD** contain millions of singleâ€‘nucleotide variants (SNVs) labelled *benign*, *pathogenic* or *uncertain*.  Correctly predicting a variantâ€™s clinical significance accelerates genetic diagnosis, pharmacogenomics and precisionâ€‘medicine workflows.  Classic tools ignore **population context** even though allele frequencies differ widely across ancestries.  

Our contribution:
* a **populationâ€‘aware feature pipeline** (pop Ã— gene & pop Ã— consequence interactions).
* comparison against equivalent *populationâ€‘agnostic* models.
* fairness and maximumâ€‘adverseâ€‘excursion (MAEÂ pips) analyses.

---
## 2Â Â Dataset & Nullâ€‘Filtering<a name="2-dataset--null-filtering"></a>
| Source | RowsÂ (raw) | RowsÂ after filtering | Notes |
|--------|-----------:|---------------------:|-------|
| Aggregated ClinVarÂ + gnomAD extract | **2â€¯847â€¯954** | **374â€¯432** | see filters below |

### 2.1Â Why ~2.5â€¯M rows were dropped
* **Missing clinical_significance**Â â†’ cannot train a supervised label (â€‘2â€¯160â€¯304).
* **Ambiguous labels** ("no assertion provided", "somatic")Â â†’ removed (â€‘420â€¯987).
* **Nonâ€‘SNV/indels** with >1 alternate alleleÂ â†’ outâ€‘ofâ€‘scope for this PoC.

These steps are critical because noisy/ambiguous labels were shown to degrade F1 by >8â€¯pp in early experiments.

### 2.2Â Feature snapshot
```
â€¢ Variantâ€‘level: position, consequence_type, gene
â€¢ Numeric: allele_freq, allele_count, sample_size, allele_length, GC_content
â€¢ Population: population_name Â (AfricanÂ Caribbean, Yoruba, â€¦)  =>  pop_gene, pop_consequence
```

---
## 3Â Â Prediction Task<a name="3-prediction-task"></a>
*Default multiâ€‘class*: **benignÂ (0) Â· pathogenicÂ (1) Â· uncertainÂ (2)**  
*Optional binary flag*: `--binary` collapses benignÂ +Â uncertain â†’ **non_pathogenicÂ (0)** vs **pathogenicÂ (1)**.

Practical uses
* Triage variants in clinical WGS reports.  
* Populationâ€‘specific risk assessment for genetic counselling.

---
## 4Â Â Process Overview<a name="4-process-overview"></a>
![pipeline](docs/img/pipeline_diagram.png)

1. **EDA**Â â†’ understand class imbalance & alleleâ€‘frequency distributions.  
2. **Feature engineering**Â â†’ sequence metrics, population interactions.  
3. **Model family comparison** (RF Â· XGB Â· LR) on *pop* vs *nonâ€‘pop* pipelines.  
4. **Hyperâ€‘parameter tuning** via `RandomizedSearchCV` (trees) & `GridSearchCV` (LR).  
5. **Holdâ€‘out evaluation** on 20Â % timeâ€‘stratified split.  
6. **Postâ€‘training** utilities: export best pickle, confusion matrices, SHAP plots.

---
## 5Â Â Exploratory Data AnalysisÂ (EDA)<a name="5-exploratory-data-analysis-eda"></a>
| Figure | What it shows |
|--------|---------------|
| ![dist](docs/img/EDA_class_distribution.png) | Class imbalance (uncertain â‰ˆÂ 17â€¯%, benign â‰ˆÂ 34â€¯%, pathogenic â‰ˆÂ 49â€¯%). |
| ![corr](docs/img/EDA_corr_matrix.png) | Numericâ€‘feature correlations (allele_freq â†” allele_countÂ ÏÂ =Â 0.91). |

Additional histograms are in `docs/img/`.

---
## 6Â Â Feature Engineering<a name="6-feature-engineering"></a>
* **Sequenceâ€‘derived**: body length, GCâ€‘content, perâ€‘base counts.  
* **Population interactions**: `pop_gene`, `pop_consequence`, `allele_freq_rel` (ratio to population mean).  
* **Encoding**: Oneâ€‘hot for categoricals; charâ€‘level `CountVectorizer` for short alleles.

---
## 7Â Â Model Fitting & Hyperâ€‘parameter Tuning<a name="7-model-fitting--hyperparameter-tuning"></a>
### 7.1Â Crossâ€‘validation leaderboard
| Model | Scaler | CVÂ Acc Â±Â SD |
|-------|--------|-------------|
| RandomForest | Standard | **0.769â€¯Â±â€¯0.004** |
| XGBoost | Standard | **0.824â€¯Â±â€¯0.003** |
| LogisticÂ Reg | Standard | 0.768â€¯Â±â€¯0.006 |

*(5â€‘fold GroupKFold by population)*

### 7.2Â Best hyperâ€‘parameters
| Family | Parameters (grid) |
|--------|-------------------|
| RF | `n_estimators=100, max_depth=15, min_samples_leaf=1` |
| XGB | `n_estimators=200, max_depth=7, lr=0.1, reg_lambda=10` |
| LR  | `C=0.1, penalty=l2, solver=liblinear` |

Full search logs live in `checkpoints/`.

---
## 8Â Â Validation & Performance Metrics<a name="8-validation--performance-metrics"></a>
### 8.1Â Holdâ€‘out results (20Â % split)
| Pipeline | Accuracy | F1â€‘w | BenignÂ F1 | PathogÂ F1 | UncertÂ F1 |
|----------|---------:|------:|-----------:|-----------:|-----------:|
| **Popâ€‘AwareÂ XGB** | **0.81** | **0.81** | 0.85 | 0.92 | 0.59 |
| Nonâ€‘PopÂ XGB | 0.81 | 0.81 | 0.85 | 0.92 | 0.60 |
| Popâ€‘AwareÂ RF | 0.75 | 0.76 | 0.76 | 0.87 | 0.63 |
| Nonâ€‘PopÂ RF | 0.77 | 0.78 | 0.77 | 0.91 | 0.65 |

*Bold*Â = best overall.  Population features gave **+6â€“9Â pp accuracy** for some African & Eastâ€‘Asian groups (see detailed table in `docs/img/pop_accuracy_bar.png`).

### 8.2Â Confusion matrices
![cm_pop](docs/img/cm_xgb_pop.png) ![cm_nonpop](docs/img/cm_xgb_nonpop.png)

### 8.3Â Fairness snapshot
*Maximum accuracy gap* (popâ€‘aware XGB) = **0.05** vs **0.10** for nonâ€‘pop.

---
## 9Â Â Production & Deployment<a name="9-production--deployment"></a>
### 9.1Â CLI inference
```bash
python -m post_training_utils.predict \
       --model models/xgboost_pop.pkl \
       --vcf   examples/one_variant.vcf
```
### 9.2Â Python API
```python
from joblib import load
from post_training_utils import featurise_variant
clf = load("models/xgboost_pop.pkl")
X = featurise_variant(vcf_record)
print(clf.predict_proba(X))
```
---
## 10Â Â Limitations & FutureÂ Improvements<a name="10-limitations--future-improvements"></a>
* **Label noise**: ClinVar â€œuncertain/conflictingâ€ may hide true pathogenicity.  
* **Population imbalance**: fewer Eastâ€‘Asian & Caribbean samples â†’ wider CIs.  
* **Shortâ€‘read bias**: large indels excluded; future work: *hg38* liftover & SV support.  
* **Deep models**: try CNN on referenceâ€‘window seq; transformer embeddings.

---
## 11Â Â Reproducing this project<a name="11-reproducing-this-project"></a>
```bash
# 1. Clone & install
conda env create -f environment.yml && conda activate ia651_genomics

# 2. Run full 3â€‘class pipeline
python genetic-variant-classifier2.py

# 3. Optional binary run
python genetic-variant-classifier2.py --binary

# 4. Export best model + plots
python -m post_training_utils.export_best --family XGBoost
```
All intermediate artefacts are cached in **checkpoints/**; complete reâ€‘run takes â‰ˆÂ 5â€¯h on an 8â€‘core laptop.

---
### âœ¨Â Acknowledgements
*Lecturer*: DrÂ Michael Gilbert(IAâ€‘651).  *Data Sources*: ClinVar, gnomAD.

